{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va avoir un problème avec la limitation à 512 tokens de BERT..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import datasets \n",
    "import evaluate\n",
    "from transformers import BertTokenizerFast, DataCollatorForTokenClassification, AutoModelForTokenClassification, TrainingArguments, Trainer, pipeline\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "conll2003 = datasets.load_dataset(\"conll2003\", trust_remote_code=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (14041, 5), 'validation': (3250, 5), 'test': (3453, 5)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003[\"train\"].features[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003['train'].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = conll2003['train'][0]\n",
    "\n",
    "tokenized_input = tokenizer(example_text[\"tokens\"], is_split_into_words=True)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\n",
    "word_ids = tokenized_input.word_ids()\n",
    "\n",
    "print(word_ids)\n",
    "\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#101 [CLS] #102 [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_text['ner_tags']), len(tokenized_input[\"input_ids\"])\n",
    "#which causes to add more input ids than tags as no tag where assigned to these two in the tokenization phase!\n",
    "#moreover, berttokenizer tokenizes into subwords so we can get further differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we need to define a function to align tokens and labels properly:\n",
    "#1 - deal with CLS/SEP tokens\n",
    "#2 - duplicate tags for subwords tokens\n",
    "\n",
    "def tokenize_and_align_labels(examples, label_all_tokens=True): \n",
    "    \"\"\"\n",
    "    Looping over tokens and tags to align them. Set to be ignored tokens to -100 (considered as padding). \n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True) \n",
    "    labels = [] \n",
    "    for i, label in enumerate(examples[\"ner_tags\"]): \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i) \n",
    "        # word_ids() => Return a list mapping the tokens\n",
    "        # to their actual word in the initial sentence.\n",
    "        # It Returns a list indicating the word corresponding to each token. \n",
    "        previous_word_idx = None \n",
    "        label_ids = []\n",
    "        # Special tokens like `<s>` and `<\\s>` are originally mapped to None \n",
    "        # We need to set the label to -100 so they are automatically ignored in the loss function.\n",
    "        for word_idx in word_ids: \n",
    "            if word_idx is None: \n",
    "                # set –100 as the label for these special tokens\n",
    "                label_ids.append(-100)\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # if current word_idx is != prev then its the most regular case\n",
    "                # and add the corresponding token                 \n",
    "                label_ids.append(label[word_idx]) \n",
    "            else: \n",
    "                # to take care of sub-words which have the same word_idx\n",
    "                # set -100 as well for them, but only if label_all_tokens == False\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100) \n",
    "                # mask the subword representations after the first subword\n",
    "                 \n",
    "            previous_word_idx = word_idx \n",
    "        labels.append(label_ids) \n",
    "    tokenized_inputs[\"labels\"] = labels \n",
    "    return tokenized_inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2848, 13934, 102]], 'token_type_ids': [[0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1]], 'labels': [[-100, 1, 2, -100]]}\n"
     ]
    }
   ],
   "source": [
    "test = tokenize_and_align_labels(conll2003['train'][1:2])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]_______________ -100\n",
      "peter_______________ 1\n",
      "blackburn___________ 2\n",
      "[SEP]_______________ -100\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.convert_ids_to_tokens(test[\"input_ids\"][0])\n",
    "for token, label in zip(tokenizer.convert_ids_to_tokens(test[\"input_ids\"][0]),test[\"labels\"][0]): \n",
    "    print(f\"{token:_<20} {label}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok it works, now lets apply it to the whole dataset\n",
    "tokenized_dataset = conll2003.map(tokenize_and_align_labels, batched=True) #batched for train/test/eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"google-bert/bert-base-uncased\", num_labels=9) #as defined by the dataset #deberta might be a good choice too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"../models/\", \n",
    "    eval_strategy=\"epoch\", \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16, \n",
    "    per_gpu_eval_batch_size=16,\n",
    "    num_train_epochs=2,  \n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1080'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)\n",
    "#this will limit the model size. Even BERT large takes ages to fine tune..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batching + padding\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the tag classes\n",
    "label_list = conll2003[\"train\"].features[\"ner_tags\"].feature.names\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = conll2003['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label_list[i] for i in example[\"ner_tags\"]] #maps id to class name\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISC {'precision': np.float64(1.0), 'recall': np.float64(1.0), 'f1': np.float64(1.0), 'number': np.int64(2)}\n",
      "ORG {'precision': np.float64(1.0), 'recall': np.float64(1.0), 'f1': np.float64(1.0), 'number': np.int64(1)}\n",
      "overall_precision 1.0\n",
      "overall_recall 1.0\n",
      "overall_f1 1.0\n",
      "overall_accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "example_eval = metrics.compute(predictions=[labels], references=[labels])\n",
    "for x in example_eval :\n",
    "    print(x, example_eval[x])\n",
    "#eval against same set so 1 is expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds): \n",
    "    \"\"\"Returns:\n",
    "    A dictionary containing the precision, recall, F1 score and accuracy.\n",
    "    \"\"\"\n",
    "    pred_logits, labels = eval_preds \n",
    "    \n",
    "    pred_logits = np.argmax(pred_logits, axis=2) \n",
    "    # the logits and the probabilities are in the same order,\n",
    "    # so we don’t need to apply the softmax\n",
    "    \n",
    "    # We remove all the values where the label is -100\n",
    "    predictions = [ \n",
    "        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100] \n",
    "        for prediction, label in zip(pred_logits, labels) \n",
    "    ] \n",
    "    \n",
    "    true_labels = [ \n",
    "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100] \n",
    "       for prediction, label in zip(pred_logits, labels) \n",
    "   ] \n",
    "    results = metrics.compute(predictions=predictions, references=true_labels) \n",
    "    return { \n",
    "   \"precision\": results[\"overall_precision\"], \n",
    "   \"recall\": results[\"overall_recall\"], \n",
    "   \"f1\": results[\"overall_f1\"], \n",
    "  \"accuracy\": results[\"overall_accuracy\"], \n",
    "  } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1756' max='1756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1756/1756 05:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.065405</td>\n",
       "      <td>0.914516</td>\n",
       "      <td>0.927509</td>\n",
       "      <td>0.920966</td>\n",
       "      <td>0.982064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.060432</td>\n",
       "      <td>0.925779</td>\n",
       "      <td>0.937689</td>\n",
       "      <td>0.931696</td>\n",
       "      <td>0.984034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/tokenizer\\\\tokenizer_config.json',\n",
       " '../models/tokenizer\\\\special_tokens_map.json',\n",
       " '../models/tokenizer\\\\vocab.txt',\n",
       " '../models/tokenizer\\\\added_tokens.json',\n",
       " '../models/tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"../models/ner_model\")\n",
    "tokenizer.save_pretrained(\"../models/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {str(i) : label for i, label in enumerate(label_list)}\n",
    "label2id = {label : str(i) for i, label in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(\"../models/ner_model/config.json\"))\n",
    "config[\"id2label\"] = id2label\n",
    "config[\"label2id\"] = label2id\n",
    "json.dump(config, open(\"../models/ner_model/config.json\",\"w\"))\n",
    "fine_tuned_model = AutoModelForTokenClassification.from_pretrained(\"../models/ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\", model=fine_tuned_model, tokenizer=tokenizer, aggregation_strategy=\"SIMPLE\") #a banger of an option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_group': 'MISC', 'score': np.float32(0.9426583), 'word': 'chevrolet colorado', 'start': 5, 'end': 23}\n",
      "{'entity_group': 'PER', 'score': np.float32(0.9819981), 'word': 'barack obama', 'start': 37, 'end': 49}\n"
     ]
    }
   ],
   "source": [
    "example = \"This Chevrolet Colorado was owned by Barack Obama.\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "for x in ner_results:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "main_df = pd.read_csv(\"../data/cleaned_data.csv\") \n",
    "df_filtered = main_df[(main_df['price'] > 500) & (main_df['price'] <= 500000) &  (main_df['odometer'] <= 500000) & (main_df['year'] >= 1980)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343285 descriptions available\n"
     ]
    }
   ],
   "source": [
    "descriptions = df_filtered.description\n",
    "print(f\"{len(descriptions)} descriptions available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it's a bit too much for now. Let's just take 1000 to start\n",
    "\n",
    "descriptions = descriptions[:1000]\n",
    "descriptions = descriptions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "a = tokenizer(descriptions)\n",
    "lengths = [len(x) for x in a[\"input_ids\"]]\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.boxplot(data=lengths)\n",
    "plt.title('Lengths of descriptions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we are above the 512 tokens limitation of BERT. The model should cut after 512 tokens automatically, let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m example \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(descriptions)\n\u001b[0;32m      4\u001b[0m example \u001b[38;5;241m=\u001b[39m descriptions[\u001b[38;5;241m970\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mtokenizer\u001b[49m(example)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokens in the sequence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m ner_results \u001b[38;5;241m=\u001b[39m nlp(example)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ner_results:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "example = random.choice(descriptions)\n",
    "\n",
    "example = descriptions[970]\n",
    "\n",
    "print(f\"{len(tokenizer(example)[\"input_ids\"])} tokens in the sequence: {example}\")\n",
    "\n",
    "ner_results = nlp(example)\n",
    "for x in ner_results:\n",
    "    if x[\"score\"] > 0.85 :\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GliNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3318be23696d4c93a04bc954931f2396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thebo\\Desktop\\AutoNLP\\venv_project\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cristiano Ronaldo dos Santos Aveiro => person\n",
      "5 February 1985 => date\n",
      "Ballon d'Or => award\n",
      "UEFA Men's Player of the Year Awards => award\n",
      "European Golden Shoes => award\n",
      "UEFA Champions Leagues => competitions\n",
      "UEFA Nations League => competitions\n"
     ]
    }
   ],
   "source": [
    "#no need to fine-tune if someone already built a very capable model:\n",
    "\n",
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_large-v2\")\n",
    "\n",
    "text = \"\"\"\n",
    "Cristiano Ronaldo dos Santos Aveiro (Portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaldu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al Nassr and the Portugal national team. Widely regarded as one of the greatest players of all time, Ronaldo has won five Ballon d'Or awards,[note 3] a record three UEFA Men's Player of the Year Awards, and four European Golden Shoes, the most by a European player. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues, the UEFA European Championship and the UEFA Nations League. Ronaldo holds the records for most appearances (183), goals (140) and assists (42) in the Champions League, goals in the European Championship (14), international goals (128) and international appearances (205). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 850 official senior career goals for club and country, making him the top goalscorer of all time.\n",
    "\"\"\"\n",
    "\n",
    "labels = [\"person\", \"award\", \"date\", \"competitions\", \"teams\"]\n",
    "\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012 Chevrolet Express Commercial Cutaway 3500, 12 FOOT ENCLOSED UTILITY BODY,, 108K - $26,990  Year: 2012 Make:Chevrolet Model:Express Commercial Cutaway Trim:3500, 12 FOOT ENCLOSED UTILITY BODY,, 108K Mileage:108,439 Stock #:VM14021 VIN:1GB0G2BA6C1158438 Trans:Automatic Color:White Vehicle Type:Service Body State:NJ Drive Train:RWD Engine:Engine, Vortec 4.8L V8 SFI (280 hp [208.8 kW] @ 5200 rpm, 295 lb-ft of torque [398.3 N-m] @ 4600 rpm) (Standard on the CG33503 and CG33803 models. With CG33503 requires (C4M) 9900 lbs. (4490 kg) GVWR or (C7A) 10,000 lbs. (4536 kg) GVWR. With CG33803 model  Notes ,,,.keywords, fence truck, fence company truck, stake body, trucks for sale near me , pick up truck for sale near me , rack truck , rack body , utility body , work trucks , liftgate , lift gate truck , work trucks for sale , flat deck , dump truck, roll back, commercial trucks, bucket truck, f150 f 150 f-150 , f250 f 250 f-250 , f350 f 350 f-350 , f450 f 450 f-450 , f550 f 550 f-550, f650 , F 150 , F 250 , F 350 , F 450 , f 550 , ford, eseries , e-series , e series cargo van , extended cab , long wheel base, SB SMALL BED , LB LONG BED , XL , XLT , Super Duty , xlt , xl , chevy, gmc, ram, Sierra , Silverado , LT , SLT , 1500 , 2500 , 2500HD , 1500HD , 3500 , 3500HD , Power Stroke , 5.7 , 6.0 , 6.4 , 6.7 , 7.3 , Diesel, Turbo Diesel , duramax , offroad , DODGE RAM , 2500 , 3500 , 4500 , 5500. c4500 , c5500 , c7500 , 4X4 , box truck , cube van , econoline , transit , e350 , e250 , e150 , work truck , commercial vehicle , e-350 , e-250 , e-150, SNOW PLOW , SNOW PLOW TRUCK , SILVERADO WORK TRUCK , GMC SIERRA , SILVERADO 2500 , box trucks , 15 foot box truck , 16 foot box truck , 16' box truck , 15' box truck , cube van , ford box truck , super duty box truck , mechanic truck , utility body , utility truck , hydraulic pump , air compressor truck , boom truck , altec , etc , versalift , service body , service truck , plumber truck , enclosed utility truck , cut away , lift gate , chevy utility body , ford utility body , chevrolet service body , flat deck , regular cab , extended cab , crew cab, 4 door , winch , winch truck , moving truck , step van , cab and chassis , cab & chassis , ford dump truck , chevy dump truck , gmc dump truck , dodge dump truck , lift-all, c6500, c7500, tire repair, tire service, truck tire, tire transport truck, fleet tire service,  Vehicle Options ABS BrakesAir ConditioningAM/FMDriver AirbagInterval WipersPassenger AirbagPower BrakesPower SteeringSteel WheelsTilt SteeringTool BoxTow Package  Vitale Motors SALES DEPT. 2030 nj 35 north south amboy NJ 08879 732-525-1040BatchID: GGCEV4Y290ID: 17134908\n",
      "Chevrolet => brand\n",
      "3500 => model\n",
      "Chevrolet => brand\n",
      "Express Commercial Cutaway => model\n",
      "CG33503 => model\n",
      "CG33803 => model\n",
      "CG33503 => model\n",
      "chevy => brand\n",
      "gmc => brand\n"
     ]
    }
   ],
   "source": [
    "labels = [\"model\", \"brand\", \"vehicle\", \"color\"]\n",
    "\n",
    "entities = model.predict_entities(descriptions[970], labels)\n",
    "\n",
    "print(descriptions[970])\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
